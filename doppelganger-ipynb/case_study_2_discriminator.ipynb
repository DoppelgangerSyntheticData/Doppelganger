{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "case_study_2_discriminator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly5WjYaMZw02",
        "outputId": "dd0a613c-da1e-45c6-8d5d-05189d80a0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.losses import *\n",
        "from keras.callbacks import *\n",
        "from keras.optimizers import *\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Check GPU setup in Colab\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "# Silence the tensorflow warning message\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "# Your expected output will be '/device:GPU:0'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.3.0\n",
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhCpKDq5Z7sn"
      },
      "source": [
        "## Load MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FQMIBn1Z4oG"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_size = x_train.shape[1]\n",
        "# Only get some data to train and test\n",
        "train_len = 60000\n",
        "test_len = 10000\n",
        "x_train = np.reshape(x_train[:train_len], [-1, image_size, image_size, 1])\n",
        "x_test = np.reshape(x_test[:test_len], [-1, image_size, image_size, 1])\n",
        "x_train = x_train.reshape(-1, 28, 28).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 28, 28).astype('float32') / 255\n",
        "y_test = y_test[:test_len]\n",
        "y_train = y_train[:train_len]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywXRT8XyZ_4H",
        "outputId": "3a8b968b-f555-4dfd-d0df-74b564e32ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UdJiR5Z_6u",
        "outputId": "3259b418-b830-4f12-abf8-10f39aa2aaa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# Change working directory to be current folder\n",
        "# os.chdir('/content/gdrive/My Drive/Your Folder Name/Your sub Folder Name')\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/case_study_2')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "case_study_2_discriminator.ipynb  vae_mnist.h5\n",
            "case_study_2_vae.ipynb\t\t  x_train_transformed.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb-iEKgMZ_9W",
        "outputId": "c217388e-189b-43eb-a39f-aaf5fa22423b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "vae = load_model('vae_mnist.h5',compile=False)\n",
        "vae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7fca302b0080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PNcWDgQi4ik"
      },
      "source": [
        "x_train_transformed = vae.predict(x_train)\n",
        "x_test_transformed = vae.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4onpCJSfjf6"
      },
      "source": [
        "from numpy import savez_compressed\n",
        "\n",
        "savez_compressed('x_train_transformed.npz', x_train_transformed)\n",
        "savez_compressed('x_test_transformed.npz', x_test_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBcwT4UckLTE"
      },
      "source": [
        "## Convolutional Neural Network Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_aGKlelkQNr"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes = 10)\n",
        "y_test = to_categorical(y_test, num_classes = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a4HbjcnmLUF"
      },
      "source": [
        "def evaluator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(324, activation = \"relu\"))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(10, activation = \"softmax\"))\n",
        "  # Define the optimizer\n",
        "  optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "  # Compile the model\n",
        "  model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  # Set a learning rate annealer\n",
        "  learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOd2x4JBmLZ9",
        "outputId": "41d4721e-3fe4-4789-c632-ec161e75b04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "!pip install livelossplot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/08/1884157a3de72d41fa97cacacafaa49abf00eba53cb7e08615b2b65b4a9d/livelossplot-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (2.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (50.3.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (20.4)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.11.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.7.4.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.13)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (7.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot) (1.1.1)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSpINS5rr2T5"
      },
      "source": [
        "img_rows=x_train[0].shape[0]\n",
        "img_cols=x_test[0].shape[1]\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
        "x_test=x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
        "\n",
        "x_train_transformed = x_train_transformed.reshape(x_train_transformed.shape[0],img_rows,img_cols,1)\n",
        "x_test_transformed = x_test_transformed.reshape(x_test_transformed.shape[0],img_rows,img_cols,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7xhkaqSmLXl"
      },
      "source": [
        "evaluator = evaluator()\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "evaluator.fit(x_train_transformed, y_train, epochs=20,\n",
        "            batch_size=10000,\n",
        "            validation_data=(x_test, y_test),\n",
        "          callbacks = [PlotLossesKeras()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG-4eX13C2kg"
      },
      "source": [
        "## Convolutional Neural Network Validator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJZpx1WHKll6"
      },
      "source": [
        "def validator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(324, activation = \"relu\"))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(10, activation = \"softmax\"))\n",
        "  # Define the optimizer\n",
        "  optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "  # Compile the model\n",
        "  model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  # Set a learning rate annealer\n",
        "  learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muhQPRVkC5EH"
      },
      "source": [
        "validator = validator()\n",
        "\n",
        "validator.fit(x_train, y_train, epochs=10,\n",
        "            batch_size=10000,\n",
        "            validation_data=(x_test_transformed, y_test),\n",
        "          callbacks = [PlotLossesKeras()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ee8Z_zbnSbG"
      },
      "source": [
        "### Comparing Evaluator & Validator Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKoNFoBhC1ly"
      },
      "source": [
        "y_pred_v = validator.predict(x_test) # Predict encoded label as 2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y_pred_v = np.argmax(y_pred_v, 1) # Decode Predicted labels\n",
        "y_test = np.argmax(y_test, 1) # Decode labels\n",
        "\n",
        "y_pred_e = evaluator.predict(x_test_transformed) # Predict encoded label as 2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "y_pred_e = np.argmax(y_pred_e, 1) # Decode Predicted labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bp6i_p3md5F"
      },
      "source": [
        "evaluator_mat = confusion_matrix(y_test, y_pred_e) # Confusion matrix\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "# Plot Confusion matrix\n",
        "plt.title('---------Confusion Matrix for Evaluator Predictions------------');\n",
        "sns.heatmap(evaluator_mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues, fmt='.0f')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('True Values');\n",
        "plt.show();\n",
        "\n",
        "\n",
        "validator_mat = confusion_matrix(y_test, y_pred_v) # Confusion matrix\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "# Plot Confusion matrix\n",
        "plt.title('-------Confusion Matrix for Validator Predictions------------');\n",
        "sns.heatmap(validator_mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues, fmt='.0f')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('True Values');\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqreq9bTmd7T"
      },
      "source": [
        "print('------------------ Evaluator Classification Report ----------------------')\n",
        "print('       ')\n",
        "print(classification_report(y_test, y_pred_e)) # Evaluator Classification report\n",
        "print('------------------ Validator Classification Report ----------------------')\n",
        "print('       ')\n",
        "print(classification_report(y_test, y_pred_v)) # Validator Classification report"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}